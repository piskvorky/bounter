{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains scripts for CountMinSketch implementation testing\n",
    "\n",
    "It uses prefix of a preprocessed wiki corpus (title_tokens) as a source, processing at most fixed amount of text. It counts the frequency of words using the python Counter (dictionary) for exact counts and then repeats the counting using Count-min sketch implementation.\n",
    "Basic statistics such as standard deviation are available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bounded_counter\n",
    "import math\n",
    "import gensim\n",
    "import numpy \n",
    "\n",
    "# some basic declarations about input\n",
    "\n",
    "# process at most this number of articles \n",
    "max_articles = 100 \n",
    "# process at most this number of total words\n",
    "max_words = 150000000\n",
    "#absolute path to corpus\n",
    "wiki_file = 'C:/rare/corpus/wiki/title_tokens.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the counter from wiki file\n",
    "# cnt (python counter) or cms (count-min sketch) can be None, it only loads into a non-empty counter\n",
    "# returns total number of loaded words\n",
    "def load(cnt, cms):\n",
    "    wiki_input = gensim.utils.smart_open(wiki_file)\n",
    "    wiki_input.seek(0)\n",
    "\n",
    "    length = 0\n",
    "    words = 0\n",
    "    for lineno, line in enumerate(wiki_input):            \n",
    "        length += 1                \n",
    "        for word in line.decode().split('\\t')[1].split():\n",
    "            if cnt is not None:\n",
    "                cnt[word] += 1\n",
    "            if cms is not None:\n",
    "                cms.increment(word)\n",
    "            words += 1\n",
    "        if (length >= max_articles or words >= max_words):\n",
    "            break\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cnt as counter with exact frequencies and cms as count-min sketch estimations,\n",
    "# provides basic statistics about the accuracy of the estimations\n",
    "# deviation: standard deviation of the estimations\n",
    "# log_deviation: standard deviation using the logcounter value instead of the derived value\n",
    "\n",
    "mks1024 = bounded_counter.CountMinSketch(width=1, depth=1, algorithm='logcounter1024')\n",
    "\n",
    "def stats(cnt, cms):\n",
    "    variance = 0\n",
    "    logvariance = 0\n",
    "    total_estimated_freq = 0\n",
    "    total_real_freq = 0\n",
    "    total_keys = 0\n",
    "    mds = 0\n",
    "    md = 0\n",
    "    mdw = ''\n",
    "    mdc = 0\n",
    "    \n",
    "    for word, real_count in cnt.items():\n",
    "        total_keys += 1\n",
    "        estimated_count = cms[word]\n",
    "        d = estimated_count - real_count\n",
    "        logd = mks1024.log_encode(estimated_count) - mks1024.log_encode(real_count) \n",
    "        total_estimated_freq += estimated_count\n",
    "        total_real_freq += real_count\n",
    "        ds = d*d\n",
    "        logds = logd * logd\n",
    "        if ds > mds:\n",
    "            md = d\n",
    "            mds = ds\n",
    "            mdw = word\n",
    "            mdc = estimated_count\n",
    "        variance += ds\n",
    "        logvariance += logds\n",
    "        \n",
    "    deviation = math.sqrt(variance / total_keys)\n",
    "    log_deviation = math.sqrt(logvariance / total_keys)\n",
    "    \n",
    "    ## Uncomment following lines for more detailed stats    \n",
    "    #print(\"Total keys: %d\" % total_keys)\n",
    "    #print(\"Total frequency reported %d (~ %f), expected %d (~ %f)\" \n",
    "    #      % (total_estimated_freq, total_estimated_freq / total_keys, total_real_freq, total_real_freq / total_keys))\n",
    "    #print(\"Deviation: %f\"% deviation)\n",
    "    #print(\"Max error: %d on key %s (expected %d, got %d)\"% (md, mdw, cnt[mdw], mdc))\n",
    "    return total_keys, deviation, log_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/a/38515297\n",
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# tests a single run with Counter already loaded\n",
    "def test(cnt, width, depth, algorithm = 'conservative'):\n",
    "    cms = bounded_counter.CountMinSketch(width, depth, algorithm)\n",
    "\n",
    "    load(None, cms)\n",
    "    (total_keys, deviation, log_deviation) = stats(cnt, cms)\n",
    "\n",
    "    cms_size = 8*width*depth\n",
    "    cnt_size = get_size(cnt)\n",
    "    result = (width, depth, algorithm, deviation, log_deviation, len(cms))\n",
    "    ## Uncomment for more test statistics\n",
    "    #print(\"%d\\t%d\\t%s\\t%f\\t%f\" % result)\n",
    "    #print(\"Tested CMS with width %d (%f of words) and depth %d\" % (width, width / total_keys, depth))\n",
    "    #print(\"Deviation: %f\" % deviation)\n",
    "    #print(\"CMS size: %d bytes, compared to %d Counter size (%f)\" % (cms_size, cnt_size, cms_size / cnt_size))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section can be used to ad-hoc test count-min sketch implementation using values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of orig: 32377 entries in 3178068 bytes from 395056 total words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 32768\ndepth: 4\nalgorithm: logcons1024\ndeviation: 4.000938\nLog deviation: 0.563151\nCardinality: 32701\nWall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_articles = 100\n",
    "max_words = 150000000\n",
    "cnt = Counter()\n",
    "words = load(cnt, None)\n",
    "print(\"Size of orig: %d entries in %d bytes from %d total words\" % (len(cnt), get_size(cnt), words))\n",
    "# modify parameters as you wish\n",
    "result = test(cnt, 32768, 4, 'logcons1024')\n",
    "\n",
    "print(\"width: %d\\ndepth: %d\\nalgorithm: %s\\ndeviation: %f\\nLog deviation: %f\\nCardinality: %d\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of orig: 22559 entries in 2608750 bytes from 210713 total words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_articles = 50\n",
    "max_words = 150000000\n",
    "\n",
    "cnt = Counter()\n",
    "words = load(cnt, None)\n",
    "results = []\n",
    "print(\"Size of orig: %d entries in %d bytes from %d total words\" % (len(cnt), get_size(cnt), words))\n",
    "for algorithm in ['basic', 'conservative', 'logcounter8', 'logcounter1024', 'logcons1024']:\n",
    "    for width in [1 << 13, 1 << 14, 1 << 15]: # all different lengths, add more. Should be power of 2\n",
    "        for depth in [4, 8]: # all different depths\n",
    "            result = test(cnt, width, depth, algorithm)\n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\t4\tbasic\t0.060609\t0.060609\t2456\n8192\t8\tbasic\t0.000000\t0.000000\t2456\n16384\t4\tbasic\t0.028571\t0.028571\t2456\n16384\t8\tbasic\t0.000000\t0.000000\t2456\n32768\t4\tbasic\t0.020203\t0.020203\t2456\n32768\t8\tbasic\t0.000000\t0.000000\t2456\n8192\t4\tconservative\t0.028571\t0.028571\t2456\n8192\t8\tconservative\t0.000000\t0.000000\t2456\n16384\t4\tconservative\t0.000000\t0.000000\t2456\n16384\t8\tconservative\t0.000000\t0.000000\t2456\n32768\t4\tconservative\t0.000000\t0.000000\t2456\n32768\t8\tconservative\t0.000000\t0.000000\t2456\n8192\t4\tlogcounter8\t4.133783\t4.133783\t2456\n8192\t8\tlogcounter8\t3.713242\t3.713242\t2456\n16384\t4\tlogcounter8\t3.805635\t3.805635\t2456\n16384\t8\tlogcounter8\t6.411628\t6.411628\t2456\n32768\t4\tlogcounter8\t4.015785\t4.015785\t2456\n32768\t8\tlogcounter8\t4.686629\t4.686629\t2456\n8192\t4\tlogcounter1024\t0.060609\t0.060609\t2456\n8192\t8\tlogcounter1024\t0.000000\t0.000000\t2456\n16384\t4\tlogcounter1024\t0.028571\t0.028571\t2456\n16384\t8\tlogcounter1024\t0.000000\t0.000000\t2456\n32768\t4\tlogcounter1024\t0.020203\t0.020203\t2456\n32768\t8\tlogcounter1024\t0.000000\t0.000000\t2456\n8192\t4\tlogcons1024\t0.028571\t0.028571\t2456\n8192\t8\tlogcons1024\t0.000000\t0.000000\t2456\n16384\t4\tlogcons1024\t0.000000\t0.000000\t2456\n16384\t8\tlogcons1024\t0.000000\t0.000000\t2456\n32768\t4\tlogcons1024\t0.000000\t0.000000\t2456\n32768\t8\tlogcons1024\t0.000000\t0.000000\t2456\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(\"%d\\t%d\\t%s\\t%f\\t%f\\t%d\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to manually sanity-test a logcounter implementation.\n",
    "The result should be in the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 104512 (1.045120 of original 100000)\nCounter difference: 71 (expected 7706, actual 7777)\n"
     ]
    }
   ],
   "source": [
    "expected = 100000\n",
    "mks = bounded_counter.CountMinSketch(1, 1, 'logcounter1024')\n",
    "for i in range(expected):\n",
    "    mks.increment(1)\n",
    "actual = mks[1]\n",
    "print(\"Got %d (%f of original %d)\" % (actual, actual / expected, expected))\n",
    "log_actual = mks.log_encode(actual)\n",
    "log_expected = mks.log_encode(expected)\n",
    "print(\"Counter difference: %d (expected %d, actual %d)\" % (log_actual - log_expected, log_expected, log_actual))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}